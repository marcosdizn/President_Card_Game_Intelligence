# ğŸ© President Intelligence

## Introduction
**President Intelligence** is a Java-based project that simulates the popular card game *President*. This project focuses on **AI-driven gameplay**, where opponents learn and improve through training. It is designed for **research and experimentation** in **artificial intelligence and game strategy**.  

This repository contains the **training source code** and **game rules**, which are used to generate intelligent agentsâ€”the AI that powers the bots in the [President Card Game App](https://github.com/marcosdizn/President_Card_Game_App) repository.

---

## âœ¨ Features
- ğŸƒ **Game Logic Implementation** â€“ Faithfully replicates the President card game rules.
- ğŸ¤– **AI-Powered Opponents** â€“ Uses a **genetic algorithm**, an unsupervised machine learning approach, for decision-making.
- ğŸ‹ï¸â€â™‚ï¸ **AI Training Scripts** â€“ Includes tools for training and evaluating the neural network.

## âš™ï¸ Setup & Execution
1. Clone the repository:
   ```sh
   git clone https://github.com/marcosdizn/President_Card_Game_Intelligence/
   ```
2. Navigate to the project folder:
   ```sh
   cd President_Card_Game_Intelligence/
   ```
3. To train the AI (Windows):
   ```sh
   ejecutar.bat
   ```
4. To test AI training:
   ```sh
   verEntrenamiento.bat
   ```

> âš ï¸ **Training Considerations:** Training can take a long time, especially with a large population. Modifying parameters in `entrenar.java` is not recommended unless you understand the impact.

## ğŸ§  AI Explanation
![AI Schema](https://github.com/marcosdizn/President_Card_Game_Intelligence/blob/main/AI_Schema.png?raw=true)

### ğŸ” Neural Network Structure
Our AI works with a **neural network** structured as follows:
- ğŸ”´ **1 Input Layer**: 57 inputs, 57 outputs (ReLU activation)
- ğŸ”µ **4 Intermediate Layers**: 57 inputs, 57 outputs (Sigmoid activation)
- ğŸŸ¢ **1 Output Layer**: 57 inputs, 12 outputs (ReLU activation)

### ğŸ“¥ Input Layer
- ğŸ´ **Inputs 0-3**: Last cards played.
- ğŸƒ **Inputs 4-13**: Player's hand.
- ğŸ—ƒï¸ **Inputs 14-51**: Cards already played.
- â³ **Inputs 52-54**: Number of cards each player has left.
- ğŸ”¥ **Input 55**: Cards in play.
- ğŸš« **Input 56**: Number of passes in a round.

### ğŸ—ï¸ Intermediate Layers
- **4 Layers** process inputs using **Sigmoid activation functions**.

### ğŸ“¤ Output Layer
- ğŸ”¢ **Outputs 0-9**: Weights assigned to each card.
- ğŸ® **Output 10**: Number of cards to play (0-4).

The AI determines the best combination based on these outputs.

## ğŸ‹ï¸â€â™‚ï¸ Training the AI
Our AI is trained using a **genetic algorithm**:
1. ğŸ² **Random Neural Networks** â€“ Initial networks have random weights and biases.
2. ğŸ† **Selection Process** â€“ The best **3 networks** from a set of **4** continue.
3. ğŸ­ **Multiple Matches** â€“ 20 games ensure strategic consistency.
4. ğŸ”„ **Recombination** â€“ The top 3 networks create the next generation.
5. ğŸ” **Iteration** â€“ The process continues until a stable strategy emerges.

### ğŸ§¬ Recombination Process
- Each child inherits **50%** of traits from two parent networks.
- **Phenotypes**:
  - ğŸ—ï¸ `w_matrix`: Rows of the weight matrix.
  - ğŸ›ï¸ `vector bias`: Bias values.
- âš¡ **Mutation**: Each gene has a probability of mutation.

### âœ… Verification
- The **best neural network** is logged periodically.
- Each network has a **unique ID** and **generation number**.
- A **user interface** allows visual verification of AI decision-making.

## ğŸ¤ Contributing  
We welcome contributions to enhance functionality and optimize performance. To contribute:  
1. Fork this repository.  
2. Create a new branch for your feature.  
3. Submit a pull request with a detailed description of changes.  
